{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Pretraing GPT-2**"
      ],
      "metadata": {
        "id": "9xi-lk3QlEWm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "HOJd9MMyxUKt",
        "outputId": "224aa669-5cb2-44fb-f9c1-21b7daa03cf6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.42.4)\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.20.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.5)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Collecting pyarrow>=15.0.0 (from datasets)\n",
            "  Downloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.4)\n",
            "Collecting requests (from transformers)\n",
            "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.5.0,>=2023.1.0 (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.5.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.7.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Downloading datasets-2.20.0-py3-none-any.whl (547 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m547.8/547.8 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.5.0-py3-none-any.whl (316 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.1/316.1 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (39.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, requests, pyarrow, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.31.0\n",
            "    Uninstalling requests-2.31.0:\n",
            "      Successfully uninstalled requests-2.31.0\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 14.0.2\n",
            "    Uninstalling pyarrow-14.0.2:\n",
            "      Successfully uninstalled pyarrow-14.0.2\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.6.1\n",
            "    Uninstalling fsspec-2024.6.1:\n",
            "      Successfully uninstalled fsspec-2024.6.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.3.1+cu121 requires nvidia-cublas-cu12==12.1.3.1; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cuda-cupti-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cuda-nvrtc-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cuda-runtime-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cudnn-cu12==8.9.2.26; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cufft-cu12==11.0.2.54; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-curand-cu12==10.3.2.106; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cusolver-cu12==11.4.5.107; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cusparse-cu12==12.1.0.106; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-nccl-cu12==2.20.5; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-nvtx-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 17.0.0 which is incompatible.\n",
            "gcsfs 2024.6.1 requires fsspec==2024.6.1, but you have fsspec 2024.5.0 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.32.3 which is incompatible.\n",
            "ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 17.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-2.20.0 dill-0.3.8 fsspec-2024.5.0 multiprocess-0.70.16 pyarrow-17.0.0 requests-2.32.3 xxhash-3.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"Trelis/tiny-shakespeare\")\n",
        "# dataset load_dataset('csv',)\n",
        "def preprocess_function(examples):\n",
        "    return tokenizer(examples['Text'], truncation=True, padding='max_length')\n",
        "from transformers import AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenized_datasets = dataset.map(preprocess_function, batched=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "793b4573358e43119a72c6c70e8765f9",
            "7eb9104c64104cb788cfc38861ee1563",
            "b944e93e1e35419d99f293558420b56f",
            "84a03ce95e4e49bdab56d69a22f1fe40",
            "c63a9c54b5ab48dda07ee39b0314266a",
            "bd28663b1e3e4cf5912513bfcc49b78a",
            "40acec715a4c4be6a1f308a4cb7227c0",
            "5a8f52c453794299a916d2631dd9c2e3",
            "fd4e26ed4c80474b908f73bd66eb0be1",
            "973af25d38cf464ea77c006835a70a04",
            "f06279f8ba8f4350b4c26080fa9f1bfc"
          ]
        },
        "id": "0WW16w4SKUZF",
        "outputId": "80bf5dcb-f2ae-4218-81b9-4e6ebbea6498",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/49 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "793b4573358e43119a72c6c70e8765f9"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer, AutoModelForCausalLM\n",
        "model = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    data_collator=data_collator,\n",
        ")"
      ],
      "metadata": {
        "id": "sizF0ztBKiII"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "PPSthXHLKwY7",
        "outputId": "7b94d8f8-903a-491b-879e-6d40febd8379",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='590' max='590' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [590/590 14:35, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>3.518700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>3.409600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>3.419800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>3.433700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>3.309300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>3.242200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>3.322300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>3.248400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>3.152700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>3.181500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>3.232800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>3.270800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>130</td>\n",
              "      <td>3.032900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>3.120600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>3.167300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>3.205900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>170</td>\n",
              "      <td>2.983400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>3.054300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>190</td>\n",
              "      <td>3.139300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>3.037200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>210</td>\n",
              "      <td>3.118400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>220</td>\n",
              "      <td>3.183400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>230</td>\n",
              "      <td>3.030000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>3.022200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>3.142800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>260</td>\n",
              "      <td>2.936100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>270</td>\n",
              "      <td>3.018800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>280</td>\n",
              "      <td>2.969400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>290</td>\n",
              "      <td>3.037200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>2.951000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>310</td>\n",
              "      <td>3.024200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>320</td>\n",
              "      <td>2.964800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>330</td>\n",
              "      <td>3.078700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>340</td>\n",
              "      <td>2.895600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>3.029300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>360</td>\n",
              "      <td>2.962400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>370</td>\n",
              "      <td>3.092900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>380</td>\n",
              "      <td>2.874400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>390</td>\n",
              "      <td>2.778100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>2.923600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>410</td>\n",
              "      <td>2.920900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>420</td>\n",
              "      <td>2.885600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>430</td>\n",
              "      <td>2.938900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>440</td>\n",
              "      <td>2.864100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>2.935100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>460</td>\n",
              "      <td>3.056200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>470</td>\n",
              "      <td>2.911100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>480</td>\n",
              "      <td>2.889600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>490</td>\n",
              "      <td>2.919900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>2.948100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>510</td>\n",
              "      <td>2.816500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>520</td>\n",
              "      <td>2.816600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>530</td>\n",
              "      <td>2.808900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>540</td>\n",
              "      <td>2.954200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>2.942300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>560</td>\n",
              "      <td>2.805600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>570</td>\n",
              "      <td>2.978600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>580</td>\n",
              "      <td>2.980900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>590</td>\n",
              "      <td>2.989000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=590, training_loss=3.048778278544798, metrics={'train_runtime': 876.7531, 'train_samples_per_second': 2.692, 'train_steps_per_second': 0.673, 'total_flos': 1233298391040000.0, 'train_loss': 3.048778278544798, 'epoch': 5.0})"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install huggingface_hub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_l7F_UKK1vj",
        "outputId": "d317d88e-366f-479f-869d-a8e92524a711"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.23.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.15.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2024.5.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (6.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2024.7.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "05cb755c9eec4b709866f2399151afc4",
            "b3a902ba471442759dfc579e67e08af4",
            "b876fce0d0544f9fa74207ee32af6640",
            "5c8c6a6d916e4fe992b1e8279ce53d30",
            "81a38930b97e400fa8e4f92e7e5519af",
            "673f50ce40944c88b80a7aac782abc12",
            "b34f133d64d248dfa5293c26f763ffd4",
            "4a497dc0a8e8404eb03b53141da92829",
            "ff28225a7d6b45deadb8e4ea449f06f4",
            "cade6777ff5749a88781a1447d1ee5da",
            "66aea27f520b4949a6a0bc6f9325c773",
            "238f35d15455418c821fe61a0fa0c215",
            "8912c1dfc76349a2b95ba858523b6a0a",
            "341358eb6e91467fbb4f6c8d352f5c2a",
            "8d522574600144e4a1a43fa34e802de9",
            "626a4ca46db04f21b75b345ea72700ff",
            "dec1052cd2524d7ba1d2560da826cbf3",
            "0eaf3b8852e8429596ec5b80c7175ae9",
            "a64426b1d354413e854eb61fb260e659",
            "43526b7fef264b549731dd159a38e0e7",
            "346c6c518886418384c1bdaa42142307",
            "c136ad68dd25452989276138e9bcdc61",
            "789c50ce2b584f85bd2e7a00445bfb29",
            "ee08248c40ae4e208b3a8984d9187847",
            "094d2c85a67c4deebc5b36176dd5392b",
            "11a9ce02e4564764a15545dfc0bf9e1d",
            "2c66d9ff66d5439a8aede14f369341d4",
            "28563ca47a2e4df6b2a0a516eb72808a",
            "ddb0e1e6260047978452d92a41556eb7",
            "cead5e95f7844711be54b5092fdbc3ed",
            "54857453f21b4cbcaee1bd3f47857a5e",
            "e9cc2961b18441c2af627b30d3150c6b"
          ]
        },
        "id": "zkAE5P5XOKUT",
        "outputId": "e8b9ff31-5cfe-4452-e74d-7fb05a1e1831"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "05cb755c9eec4b709866f2399151afc4"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.push_to_hub(\"ahmadmac/Pretrained-GPT2\")\n",
        "tokenizer.push_to_hub(\"ahmadmac/Pretrained-GPT2\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "d396dfd2000b480e94f673ede7cd8d0a",
            "3dbafac6211c4fa986c2973318cfabf4",
            "f7a960364aea4e38ba01109dad3223ad",
            "607c2969f82246a0bcb5c03ba7ab183d",
            "37c71c0ab11d4dd6ad9ad4e33d92a2bf",
            "19564eaf0df146cbbae6172401c053a8",
            "90f6919c91e1463f99153255a50bab79",
            "e3475d13d1514ab5b7d939ffc3dc4266",
            "5d71eb6f4b2f4a46947caa8abb0f1a0f",
            "b9d81f0af40f48ea9b203d5aff79666b",
            "bf496a54773142b5a384debb72c40507"
          ]
        },
        "id": "J9ZKLYrBONgE",
        "outputId": "968884a4-bc88-44f5-fe14-f62286004d37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/993 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d396dfd2000b480e94f673ede7cd8d0a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/ahmadmac/Pretrained-GPT2/commit/7c642d76babedec66fdc925b1bdf0113c192ee09', commit_message='Upload tokenizer', commit_description='', oid='7c642d76babedec66fdc925b1bdf0113c192ee09', pr_url=None, pr_revision=None, pr_num=None)"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"ahmadmac/Pretrained-GPT2\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\"ahmadmac/Pretrained-GPT2\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397,
          "referenced_widgets": [
            "672ff42748f543a0999965066b31310b",
            "5550c46ff0a84a60a9ef69ecf2ac7994",
            "fd4d9df9257a488483ff8d99ea948e10",
            "809e9f8d6b044b3192b05a737e458c2d",
            "33997ee4f05945c7b77db71f9fee1393",
            "b2be2bb0e24b4c72b81fa95d961b2606",
            "86245a3c733f44fc8f868e55df545521",
            "c3bab8955f464cb1a66f5e0222841183",
            "e90cea8aecc949e4bb91c1d26ed3f61c",
            "7bcd9b487b9743b1a84111bfbbf3b06b",
            "4334451312714a39a0a9f56a4a19901f",
            "e87ee6aedf9342c69da0e5d23c2dfd4a",
            "0cfa02b9f5484619961290802ed4311c",
            "5d84ad91f14f4c0da3cf3c93cb9d5975",
            "df80b32d71454448a2218b54c143963b",
            "cb586ffd8b124063b4c69eff328575eb",
            "d162de3142d842f1a565f4a0bb809796",
            "86c6d9aa3392431fa2c5a8ae32fb6201",
            "92227dc5c84f41768cfe45ee3c79df07",
            "152da14c8df2420092533da5f4de5fa2",
            "a5ef5d88cdec4379ac92290dd9e91a08",
            "c6ee208cdd2c4ee99687acd7036bf66a",
            "b2482b837de44d57bd9f59a23ad5da29",
            "ea11405fdd2e4745aaea1c7b79c09e08",
            "2fc19da763db4f8ab6f0c7cb863c4582",
            "95ed6f4eab7f4a78951d82b62f5ca5d1",
            "b2b88dc019bb4e3983e2149bdcf9e40e",
            "01fb115b3c564bdf8c1788a93b1918e1",
            "6327476f38b849b680c493bb407e1b50",
            "da0b62732b1a47d38673bd6fb0fdd171",
            "2159753a731c420c89f18d3d5191d421",
            "482dc9d15cf04c24b23d82a02fea91b5",
            "412be33a157c4d35b76801a4af13d776",
            "bd02fd7d316f46b59b214dc3b84bb760",
            "32778e50d32241a6b4847c268071ce53",
            "3116e10e65b6461a9844f37422a1cc91",
            "032315a139154fe1ad6baaac445a8b04",
            "a2cf10bb9f7d421da4dcb366996b3a86",
            "8a07e615a8ba415987af89291620eb1a",
            "e4704af24daa4f0e97cf021368305f8d",
            "ea0d9bd70599443e8d830c8ef4bd173d",
            "75adea1df3654e0d8564f8a7d8bb7994",
            "1a33366f202f4884a2d2bc7f00f6dd6d",
            "ece3762089904ce4b708a6c294e76375",
            "aa8b78a1655f4511830803efeb66883c",
            "96f2381c04994aa1b54ad09e1e95f705",
            "f928f0c0d2e74d7e94e2fd726aaa2c65",
            "74f8c273e90741b99767bc1762e5ef76",
            "67d1a5175df3404a999eefe1ade936e7",
            "2e45062344eb41fc99edd337b674bd26",
            "487e44c85d014746974aabd9d34f9f98",
            "c6b7549a84564022ae101ab747e47a1d",
            "88797ccb50874db99cacd3f7a94a7a6d",
            "b18fb82fe41945979edb640dc96addb3",
            "98f24ac4f00f47c9b00fc8a44af45950",
            "4a14beb254634246bfecd3925d40d662",
            "b41225d71a744aed87388e2f02b9d6f0",
            "50a8a698da1e406392319f4ee5acaf27",
            "835cc9f2f43346b3a855cbce7e12e50c",
            "b651547a963846c5aa68254859c76bc8",
            "35cc10b765a145d68998d32bea04370d",
            "4d3b308de6fa4fccacc2f4a8439a17bf",
            "332d9466f5bc41bcba1c027cfb5c44b4",
            "946d84e94e5841a5b3edb0a2fa0aaaa4",
            "eb830bdfddaf4beba616698afdd8743d",
            "1c7504cecf26411c9e208936133e874f",
            "8dbfde15a3f7433eafd3bd51d51cebfe",
            "2ef5f679ffad47c88759aa1faa3fc079",
            "f3bace2150c648fd830fd2d732cb1e3f",
            "91a88614024d4d8b8f57f7fc15728300",
            "36f791bb2db047bcb9055807e8ffd002",
            "dd94f0aca8cc484aae9f66b28d4361c0",
            "4e74dfba37f5484e904f47e796885f2c",
            "966c785bfffc4bf6baf851a6dd4c1018",
            "a778ca0f9aea4f54bca55fb065e03ea6",
            "66ba0c4146d94d40897ae523f36a7898",
            "5b080dc6b27a425fa923ddb76cf30cb4",
            "21c832b72654456baddb3d8a73d702a0",
            "266b81fb9f594f9592462f3693a75ba0",
            "b9762a69bd974bcca1d094063d2e139a",
            "246796188ffe478aa85f12c128367f86",
            "7661b9ff0b10448fa5ce1699364bd38a",
            "e27d839cfd6b42ad9f107d2f1a60f07c",
            "23d851fc0bbf41b8a1e56716b3dc00b4",
            "eadf88fd13124f59a9671c071244867b",
            "0069a5466c7446cb8e354163a7254d88",
            "4f782e8532e247ef8525afe06b27b0f9",
            "84ae49386c374a0e9eaf0162adbe8be5"
          ]
        },
        "collapsed": true,
        "id": "7kKUXE0OPpiJ",
        "outputId": "ed94a178-303d-454b-e36b-3b4f54131915"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/476 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "672ff42748f543a0999965066b31310b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e87ee6aedf9342c69da0e5d23c2dfd4a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b2482b837de44d57bd9f59a23ad5da29"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bd02fd7d316f46b59b214dc3b84bb760"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/131 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aa8b78a1655f4511830803efeb66883c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/907 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4a14beb254634246bfecd3925d40d662"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/498M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8dbfde15a3f7433eafd3bd51d51cebfe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/119 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "21c832b72654456baddb3d8a73d702a0"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_response(input_text):\n",
        "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
        "    output = model.generate(input_ids, max_length=100, num_return_sequences=1, pad_token_id=tokenizer.eos_token_id)\n",
        "    response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "    return response"
      ],
      "metadata": {
        "id": "OgeNMVbcQ6jv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(get_response(\"I have heard you say that\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RnPD3qRIUbMn",
        "outputId": "b8184ff8-597d-4749-ac84-b806928efcd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I have heard you say that the Lord of the North is a man of great power, and that he hath made a great deal of peace with the people.\n",
            "\n",
            "KING RICHARD II:\n",
            "I have heard you say that the Lord of the North is a man of great power, and that he hath made a great deal of peace with the people.\n",
            "\n",
            "KING RICHARD II:\n",
            "I have heard you say that the Lord of the North is a man of great power,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments, DataCollatorForLanguageModeling\n",
        "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    overwrite_output_dir=True,\n",
        "    num_train_epochs=5,\n",
        "    save_total_limit=2,\n",
        "    save_steps=200,\n",
        "    per_device_train_batch_size=4,\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_steps=10,\n",
        "    logging_dir='./logs',\n",
        ")"
      ],
      "metadata": {
        "id": "y8-WnSevKal2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}